# SLED
The official repository for Efficient Long-Text Understanding Using Short-Text Models (Ivgi et al., 2022) [paper](https://arxiv.org/abs/2208.00748.pdf).
The data for this paper is based on the [SCROLLS](https://huggingface.co/datasets/tau/scrolls) ([paper](https://arxiv.org/pdf/2201.03533.pdf)), the [SQuAD 1.1](https://huggingface.co/datasets/squad) dataset and the [HotpotQA](https://huggingface.co/datasets/hotpot_qa) dataset.
It doesn't contain any unpblished data, but includes the configuration needed for the paper.

The code will be uploaded here in the following week.

If you use this repository, please cite as below:
```
@inproceedings{Ivgi2022EfficientLU,
  title={Efficient Long-Text Understanding with Short-Text Models},
  author={Maor Ivgi and Uri Shaham and Jonathan Berant},
  year={2022}
}
```
